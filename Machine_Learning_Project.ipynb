{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Project**"
      ],
      "metadata": {
        "id": "wkco0Ojyw6rX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Project Topic:** Image Filteration And Noise Reduction using CNN"
      ],
      "metadata": {
        "id": "CoZlrlezxYqW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Man5qLBoA0ly"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Course:** Introduction To Machine Learning"
      ],
      "metadata": {
        "id": "xQG4wDc3wzrB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Group Members:**\n",
        "\n",
        "\n",
        "1.   Shahzaib Hamza (FA20-BSSE-0062)\n",
        "2.   Sarfaraz Illahi Soomro (FA20-BSSE-0027)\n",
        "3.   Syed Maher Ali Shah (FA20-BSSE-0061)\n",
        "\n"
      ],
      "metadata": {
        "id": "6KtQ3sSmw_ZW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Section 1:**(Importing Necessary Libraries)"
      ],
      "metadata": {
        "id": "e7uk_rJag2Zf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow numpy matplotlib opencv-python ipywidgets\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from google.colab import files\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_fNRgT_hB8P",
        "outputId": "496b36e5-c27b-40d4-8390-bca3f08f7d30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (7.7.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.1)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (5.5.6)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (3.6.6)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (7.34.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (3.0.11)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.3.3)\n",
            "Collecting jedi>=0.16 (from ipython>=4.0.0->ipywidgets)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (3.0.45)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (4.9.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets) (6.5.5)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.1.4)\n",
            "Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (24.0.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (23.1.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.7.2)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.5.4)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.6.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.20.0)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.1.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.13)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.1->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.2.2)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.2.4)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.9.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.12.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.4)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.3.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.10.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.0)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.19.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.19.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.2.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.18.1)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.10/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.24.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.16.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.5)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.22)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.2.1)\n",
            "Installing collected packages: jedi\n",
            "Successfully installed jedi-0.19.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Section 2:** MNIST Denoising Model Data Preprocessing"
      ],
      "metadata": {
        "id": "ydnaF0fyhn2I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code snippet loads the MNIST dataset, a collection of handwritten digits, for training a denoising model. Firstly, it loads the dataset and then preprocesses it by scaling the pixel values to a range between 0 and 1. Finally, it expands the dimensions of the data to include a channel dimension, necessary for convolutional operations. This prepares the dataset for training a denoising model effectively."
      ],
      "metadata": {
        "id": "dccxdhAghsIg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, _), (x_test, _) = mnist.load_data()\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "x_train = np.expand_dims(x_train, axis=-1)\n",
        "x_test = np.expand_dims(x_test, axis=-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jG5kOmofh_nX",
        "outputId": "5c77bd66-a1ad-48cb-b89b-3eeac6509591"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Section 3:** (interactive Image Processing Toolbox with Denoising)"
      ],
      "metadata": {
        "id": "yvXoyba-m9Cm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This script sets up an interactive environment for image processing, focusing on denoising. It begins by loading the necessary libraries and defining functions for image manipulation. The MNIST dataset is preprocessed to train a denoising model, which is then utilized in the interactive environment. Users can upload an image and apply various filters such as grayscale conversion, edge detection, sharpening, and more. Additionally, they can add salt-and-pepper noise to images and denoise them using the trained model. The interface is enhanced with interactive widgets for ease of use."
      ],
      "metadata": {
        "id": "BQjrN3a7nBgx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "denoising_model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(28, 28, 1)),\n",
        "    MaxPooling2D((2, 2), padding='same'),\n",
        "    Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
        "    MaxPooling2D((2, 2), padding='same'),\n",
        "    Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
        "    UpSampling2D((2, 2)),\n",
        "    Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
        "    UpSampling2D((2, 2)),\n",
        "    Conv2D(1, (3, 3), activation='sigmoid', padding='same')\n",
        "])\n",
        "denoising_model.compile(optimizer='adam', loss='binary_crossentropy')"
      ],
      "metadata": {
        "id": "0P6cKXfenPnf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Section 4:** (Denoising Model Training)"
      ],
      "metadata": {
        "id": "2eSwFrwTninq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this step, the denoising model is trained using the prepared noisy data. Gaussian noise with a specified factor is added to the MNIST dataset, ensuring variability in training samples. The noisy images are clipped to maintain pixel values within the valid range. The model is then trained for a specified number of epochs with a defined batch size. Training progress is monitored using validation data. This step aims to optimize the model for effective denoising performance."
      ],
      "metadata": {
        "id": "lKqtN45gxryl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "noise_factor = 0.5\n",
        "x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape)\n",
        "x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape)\n",
        "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
        "x_test_noisy = np.clip(x_test_noisy, 0., 1.)\n",
        "\n",
        "denoising_model.fit(x_train_noisy, x_train, epochs=10, batch_size=128, shuffle=True, validation_data=(x_test_noisy, x_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEM8zXpbod_A",
        "outputId": "4e960e1d-a308-4e69-d32e-7f2fc171ff4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "469/469 [==============================] - 122s 256ms/step - loss: 0.1697 - val_loss: 0.1169\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 115s 245ms/step - loss: 0.1136 - val_loss: 0.1087\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 116s 247ms/step - loss: 0.1075 - val_loss: 0.1054\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 114s 243ms/step - loss: 0.1046 - val_loss: 0.1030\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 114s 244ms/step - loss: 0.1028 - val_loss: 0.1012\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 117s 249ms/step - loss: 0.1015 - val_loss: 0.1001\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 115s 245ms/step - loss: 0.1004 - val_loss: 0.0993\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 115s 244ms/step - loss: 0.0997 - val_loss: 0.0985\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 112s 240ms/step - loss: 0.0990 - val_loss: 0.0985\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 117s 250ms/step - loss: 0.0985 - val_loss: 0.0977\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7fd595092c80>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Section 5:** Saving The Denoising Model"
      ],
      "metadata": {
        "id": "AKnTWDkRtMnL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "denoising_model.save('denoising_cnn_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kv_yXpZ-tSSp",
        "outputId": "393fb0a2-150a-4c01-f8f7-f8a9c758a90a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Section 6:** Defining Image Processing Helper Functions"
      ],
      "metadata": {
        "id": "zFviQUeStd5h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section defines helper functions essential for image processing tasks within the interactive environment. The upload_and_preprocess_image function facilitates the upload and preprocessing of images, converting them to the required format for processing and denoising. The apply_filter function applies a specified model's filter to an input image, returning the filtered result. These functions streamline the image processing workflow, enabling efficient manipulation and denoising of uploaded images."
      ],
      "metadata": {
        "id": "RFzO6W-ltyw4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def upload_and_preprocess_image():\n",
        "    uploaded = files.upload()\n",
        "    for fn in uploaded.keys():\n",
        "        image = cv2.imread(fn)\n",
        "        colored_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        gray_image = cv2.resize(gray_image, (28, 28))\n",
        "        gray_image = gray_image.astype('float32') / 255.0\n",
        "        gray_image = np.expand_dims(gray_image, axis=-1)\n",
        "        gray_image = np.expand_dims(gray_image, axis=0)\n",
        "        return colored_image, gray_image, fn\n",
        "\n",
        "def apply_filter(model, image):\n",
        "    return model.predict(image)"
      ],
      "metadata": {
        "id": "o8pvjjEhtdYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Section 7:** Image Display And Analysis Function"
      ],
      "metadata": {
        "id": "0afqlkTxuOZ5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function, display_image, is responsible for displaying the original and filtered images side by side, along with their corresponding histograms. It creates a figure with three subplots: the first subplot displays the original image, the second displays the filtered image with a specified title, and the third shows the histogram of pixel intensity values in the filtered image. This function aids in visualizing the effects of various filters and provides insights into the distribution of pixel values within the processed image."
      ],
      "metadata": {
        "id": "EiHN7zMXuX3R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def display_image(original, filtered, title):\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.imshow(original)\n",
        "    plt.title('Original')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.imshow(filtered, cmap='gray')\n",
        "    plt.title(title)\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.hist(filtered.flatten(), bins=256, color='gray', alpha=0.7)\n",
        "    plt.title('Histogram')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "RItQLE-duh5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Section 8:** Image Processing Filters and Manipulations"
      ],
      "metadata": {
        "id": "vi1Lmmm8uwl5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This set of functions encompasses various image processing filters and manipulations for enhancing or modifying images. convert_to_grayscale converts a colored image to grayscale. apply_edge_detection applies an edge detection filter to detect edges in the image. apply_sharpening sharpens the image by applying a specific kernel. add_salt_and_pepper_noise adds salt-and-pepper noise to the image to simulate noisy conditions. apply_denoising utilizes the denoising model to remove noise from the image. mean_pass_filter applies a mean pass filter to the image to blur it slightly. convert_green_to_red converts green regions in the image to red, altering the color composition. These functions offer a range of options for image manipulation and enhancement within the interactive environment."
      ],
      "metadata": {
        "id": "-pb3kyNEvCmR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_grayscale(image):\n",
        "    return cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "def apply_edge_detection(image):\n",
        "    kernel = np.array([[-1, -1, -1], [-1, 8, -1], [-1, -1, -1]])\n",
        "    edge_detected = cv2.filter2D(image, -1, kernel)\n",
        "    return edge_detected\n",
        "\n",
        "def apply_sharpening(image):\n",
        "    kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])\n",
        "    sharpened = cv2.filter2D(image, -1, kernel)\n",
        "    return sharpened\n",
        "\n",
        "def add_salt_and_pepper_noise(image, amount=0.04, salt_vs_pepper=0.5):\n",
        "    noisy_image = image.copy()\n",
        "    num_salt = np.ceil(amount * image.size * salt_vs_pepper)\n",
        "    num_pepper = np.ceil(amount * image.size * (1.0 - salt_vs_pepper))\n",
        "\n",
        "    # Add Salt noise\n",
        "    coords = [np.random.randint(0, i - 1, int(num_salt)) for i in image.shape]\n",
        "    noisy_image[tuple(coords)] = 1\n",
        "\n",
        "    # Add Pepper noise\n",
        "    coords = [np.random.randint(0, i - 1, int(num_pepper)) for i in image.shape]\n",
        "    noisy_image[tuple(coords)] = 0\n",
        "\n",
        "    return noisy_image\n",
        "\n",
        "def apply_denoising(image):\n",
        "    return apply_filter(denoising_model, image).reshape(28, 28)\n",
        "\n",
        "def mean_pass_filter(image):\n",
        "    kernel = np.ones((3, 3), np.float32) / 9\n",
        "    return cv2.filter2D(image, -1, kernel)\n",
        "\n",
        "def convert_green_to_red(image):\n",
        "    red_image = image.copy()\n",
        "    lower_green = np.array([0, 100, 0])\n",
        "    upper_green = np.array([100, 255, 100])\n",
        "    mask = cv2.inRange(red_image, lower_green, upper_green)\n",
        "    red_image[mask > 0] = [255, 0, 0]\n",
        "    return red_image"
      ],
      "metadata": {
        "id": "QZSu5ivqvFQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Section 9:** Interactive Image Processing Widgets"
      ],
      "metadata": {
        "id": "1eJZtBcdvww5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This step introduces interactive widgets to facilitate real-time image processing and manipulation. After uploading and preprocessing an image, users can interact with various buttons to apply different filters and transformations. The provided buttons include options for converting the image to grayscale, performing edge detection, sharpening the image, adding salt-and-pepper noise, denoising the image using the trained model, applying a mean pass filter, and converting green regions to red. Each button click triggers a specific image processing function, and the results are displayed instantly for user inspection. This interactive interface empowers users to explore different image processing techniques effortlessly."
      ],
      "metadata": {
        "id": "mdA0ojgOv5E1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "colored_image, gray_image, filename = upload_and_preprocess_image()\n",
        "\n",
        "plt.imshow(colored_image)\n",
        "plt.title('Original Image')\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "buttons = {\n",
        "    'Grayscale': widgets.Button(description='Convert to Grayscale'),\n",
        "    'Edge Detection': widgets.Button(description='Edge Detection'),\n",
        "    'Sharpening': widgets.Button(description='Sharpening'),\n",
        "    'Add Noise': widgets.Button(description='Add Salt and Pepper Noise'),\n",
        "    'Denoising': widgets.Button(description='Denoising'),\n",
        "    'Mean Pass Filter': widgets.Button(description='Mean Pass Filter'),\n",
        "    'Green to Red': widgets.Button(description='Convert Green to Red')\n",
        "}\n",
        "\n",
        "def on_grayscale_clicked(b):\n",
        "    grayscale_image = convert_to_grayscale(colored_image)\n",
        "    display_image(colored_image, grayscale_image, 'Grayscale')\n",
        "\n",
        "def on_edge_detection_clicked(b):\n",
        "    edge_detected_image = apply_edge_detection(cv2.cvtColor(colored_image, cv2.COLOR_RGB2GRAY))\n",
        "    display_image(colored_image, edge_detected_image, 'Edge Detection')\n",
        "\n",
        "def on_sharpening_clicked(b):\n",
        "    sharpened_image = apply_sharpening(cv2.cvtColor(colored_image, cv2.COLOR_RGB2GRAY))\n",
        "    display_image(colored_image, sharpened_image, 'Sharpened')\n",
        "\n",
        "def on_add_noise_clicked(b):\n",
        "    noisy_image = add_salt_and_pepper_noise(colored_image)\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(colored_image)\n",
        "    plt.title('Original')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(noisy_image)\n",
        "    plt.title('Noisy Image')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "def on_denoising_clicked(b):\n",
        "    noisy_image = add_salt_and_pepper_noise(colored_image)\n",
        "    denoised_image = apply_denoising(gray_image)\n",
        "    display_image(noisy_image, colored_image, 'Denoised')\n",
        "\n",
        "def on_mean_pass_filter_clicked(b):\n",
        "    mean_filtered_image = mean_pass_filter(convert_to_grayscale(colored_image))\n",
        "    display_image(colored_image, mean_filtered_image, 'Mean Pass Filter')\n",
        "\n",
        "def on_green_to_red_clicked(b):\n",
        "    red_image = convert_green_to_red(colored_image)\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(colored_image)\n",
        "    plt.title('Original')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(red_image)\n",
        "    plt.title('Green to Red')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "buttons['Grayscale'].on_click(on_grayscale_clicked)\n",
        "buttons['Edge Detection'].on_click(on_edge_detection_clicked)\n",
        "buttons['Sharpening'].on_click(on_sharpening_clicked)\n",
        "buttons['Add Noise'].on_click(on_add_noise_clicked)\n",
        "buttons['Denoising'].on_click(on_denoising_clicked)\n",
        "buttons['Mean Pass Filter'].on_click(on_mean_pass_filter_clicked)\n",
        "buttons['Green to Red'].on_click(on_green_to_red_clicked)\n",
        "\n",
        "for button in buttons.values():\n",
        "    display(button)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "E63H39Kjv6JS",
        "outputId": "f3e4d228-85fa-4699-e687-095d73966c3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'upload_and_preprocess_image' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f2164291d2a4>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcolored_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgray_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupload_and_preprocess_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolored_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Original Image'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'upload_and_preprocess_image' is not defined"
          ]
        }
      ]
    }
  ]
}